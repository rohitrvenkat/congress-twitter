{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import json\n",
    "from datetime import datetime, date\n",
    "import unidecode as uni\n",
    "import pandas as pd\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "assigned-invention",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/10/14 22:35:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Create spark session\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "institutional-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rdd from twitter json\n",
    "tweetsRDD = spark.sparkContext.textFile('../data/congress-115-116-tweets.jsonl').map(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "confident-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create return_date function\n",
    "def return_date(created_at):\n",
    "    return datetime.strptime(created_at, '%a %b %d %H:%M:%S +0000 %Y').date()\n",
    "\n",
    "# Perform some initial filtering\n",
    "tweetsRDD = tweetsRDD.filter(lambda tweet: return_date(tweet['created_at']) >= date(2017, 1, 3))\n",
    "tweetsRDD = tweetsRDD.filter(lambda tweet: 'RT @' not in tweet['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "running-hungarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Get twitter accounts and users \n",
    "twitterAccountsRDD = (tweetsRDD\n",
    "                      .map(lambda tweet: (tweet['user']['screen_name'], tweet['user']['name']))\n",
    "                      .reduceByKey(lambda a, b: a)\n",
    "                     )\n",
    "\n",
    "# Convert to dataframe\n",
    "twitter_accounts = (twitterAccountsRDD\n",
    "                    .map(lambda kv: (kv[0], uni.unidecode(kv[1])))\n",
    "                    .toDF(['twitter_account', 'twitter_user'])\n",
    "                    .toPandas()\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "structural-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in party info\n",
    "party_info = pd.read_csv('../data/congress-wikiscrape.csv')\n",
    "\n",
    "# Create empty dataframe\n",
    "twitter_df = pd.DataFrame(columns = ['twitter_account', 'twitter_user', 'full_name', 'party']) \n",
    "\n",
    "# Loop through twitter_accounts rows\n",
    "for twitter_index, twitter_row in twitter_accounts.iterrows():\n",
    "\n",
    "    # Store twitter_account, twitter_user\n",
    "    twitter_account = twitter_row['twitter_account']\n",
    "    twitter_user = twitter_row['twitter_user']\n",
    "\n",
    "    # Reset match counters\n",
    "    first_name_matches = 0\n",
    "    last_name_matches = 0\n",
    "    perfect_match = False\n",
    "\n",
    "    # Loop through party_info rows\n",
    "    for party_info_index, party_info_row in party_info.iterrows():\n",
    "\n",
    "        # Store full_name, first_name, last_name, party\n",
    "        full_name = party_info_row['full_name']\n",
    "        first_name = party_info_row['first_name']\n",
    "        last_name = party_info_row['last_name']\n",
    "        party = party_info_row['party']\n",
    "        \n",
    "        # Append to dataframe if both first_name and last_name in twitter_user (i.e. perfect match)\n",
    "        if all([name in twitter_user.lower() for name in [first_name, last_name]]):\n",
    "            \n",
    "            twitter_df = twitter_df.append({'twitter_account': twitter_account, \n",
    "                                            'twitter_user': twitter_user,\n",
    "                                            'full_name': full_name, \n",
    "                                            'party': party}, ignore_index = True)\n",
    "            \n",
    "            perfect_match = True           \n",
    "            break\n",
    "            \n",
    "        # Store first name match if first_name in twitter_user\n",
    "        elif first_name in twitter_user.lower():\n",
    "            \n",
    "            first_name_match = {'twitter_account': twitter_account,\n",
    "                                'twitter_user': twitter_user,\n",
    "                                'full_name': full_name, \n",
    "                                'party': party}\n",
    "            \n",
    "            first_name_matches += 1\n",
    "            \n",
    "        # Store last name match if last_name in twitter_user\n",
    "        elif last_name in twitter_user.lower():\n",
    "            \n",
    "            last_name_match = {'twitter_account': twitter_account,\n",
    "                               'twitter_user': twitter_user,\n",
    "                               'full_name': full_name,\n",
    "                               'party': party}\n",
    "            \n",
    "            last_name_matches += 1\n",
    "            \n",
    "    # Run if perfect match doesn't exist after looping through all party_info rows\n",
    "    if not perfect_match:\n",
    "        \n",
    "        # Append first_name_match to dataframe if only 1 first_name match exists\n",
    "        if first_name_matches == 1:\n",
    "            \n",
    "            twitter_df = twitter_df.append(first_name_match, ignore_index = True)\n",
    "            \n",
    "        # Append last_name_match to dataframe if only 1 last_name match exists\n",
    "        elif last_name_matches == 1:\n",
    "            \n",
    "            twitter_df = twitter_df.append(last_name_match, ignore_index = True)\n",
    "            \n",
    "        # Append incomplete info to dataframe if multiple or no matches exist\n",
    "        else:\n",
    "            \n",
    "            twitter_df = twitter_df.append({'twitter_account': twitter_account,\n",
    "                                            'twitter_user': twitter_user,\n",
    "                                            'full_name': '', \n",
    "                                            'party': ''}, ignore_index = True)\n",
    "\n",
    "# Write dataframe to csv\n",
    "twitter_df.to_csv(\"../data/twitter-account-with-party.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "south-default",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     986\n",
       "False     19\n",
       "Name: party, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matched 986 of 1005 twitter accounts with party\n",
    "display(twitter_df['party'].isin(['D','R']).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "minute-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in manually updated csv\n",
    "twitter_df = pd.read_csv('../data/twitter-account-with-party-final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "portuguese-drama",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Get follower counts\n",
    "followerCountsRDD = (tweetsRDD\n",
    "                     .map(lambda tweet: (tweet['user']['screen_name'], tweet['user']['followers_count']))\n",
    "                     .reduceByKey(max)\n",
    "                     )\n",
    "\n",
    "# Convert to dataframe\n",
    "follower_counts = (followerCountsRDD\n",
    "                   .map(lambda kv: (kv[0], kv[1]))\n",
    "                   .toDF(['twitter_account', 'followers'])\n",
    "                   .toPandas()\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "regional-wallace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Get tweet counts\n",
    "tweetCountsRDD = (tweetsRDD\n",
    "                  .map(lambda tweet: (tweet['user']['screen_name'], 1))\n",
    "                  .reduceByKey(lambda a, b: a + b)\n",
    "                 )\n",
    "\n",
    "# Convert to dataframe\n",
    "tweet_counts = (tweetCountsRDD\n",
    "                .map(lambda kv: (kv[0], kv[1]))\n",
    "                .toDF(['twitter_account', 'tweet_count'])\n",
    "                .toPandas()\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "casual-amazon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Get retweet counts\n",
    "retweetCountsRDD = (tweetsRDD\n",
    "                    .map(lambda tweet: (tweet['user']['screen_name'], tweet['retweet_count']))\n",
    "                    .reduceByKey(lambda a, b: a + b)\n",
    "                   )\n",
    "\n",
    "# Convert to dataframe\n",
    "retweet_counts = (retweetCountsRDD\n",
    "                  .map(lambda kv: (kv[0], kv[1]))\n",
    "                  .toDF(['twitter_account', 'retweets_total'])\n",
    "                  .toPandas()\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rough-framework",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Get favorite counts\n",
    "favoriteCountsRDD = (tweetsRDD\n",
    "                     .map(lambda tweet: (tweet['user']['screen_name'], tweet['favorite_count']))\n",
    "                     .reduceByKey(lambda a, b: a + b)\n",
    "                    )\n",
    "\n",
    "# Convert to dataframe\n",
    "favorite_counts = (favoriteCountsRDD\n",
    "                   .map(lambda kv: (kv[0], kv[1]))\n",
    "                   .toDF(['twitter_account', 'favorites_total'])\n",
    "                   .toPandas()\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d39b8ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine dataframes\n",
    "data_frames = [twitter_df, follower_counts, tweet_counts, retweet_counts, favorite_counts]\n",
    "summary_df = reduce(lambda left, right: pd.merge(left, right, on = ['twitter_account']), data_frames)\n",
    "\n",
    "# Calculate per tweet statistics\n",
    "summary_df['retweets_per_tweet'] = summary_df['retweets_total'] / summary_df['tweet_count']\n",
    "summary_df['favorites_per_tweet'] = summary_df['favorites_total'] / summary_df['tweet_count']\n",
    "\n",
    "# Write to csv\n",
    "summary_df.to_csv(\"../data/twitter-accounts-summary.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter",
   "language": "python",
   "name": "twitter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
